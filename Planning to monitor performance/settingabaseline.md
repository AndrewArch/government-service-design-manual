#Setting a baseline
Collect and aggregate performance information from multiple sources and across multiple channels in order to establish a 'baseline' against which changes to the service will be judged. This will help you pinpoint the effect of your initiatives, and identify what worked.

##Guidance
* Have you collected data on costs, usage and performance?
* Have you collected performance data from digital and non-digital channels?
* Do you know how many people use the service, by channel?
* Do you know who your users are in terms of age, disability, socio-economic group and internet usage?
* Have you aggregated performance data to enable it to be easily combined?
* Have you compared your performance with similar types of service (e.g. by transaction category)?

##Why we do this
It is good practice to look at performance trends over time, rather than take a snapshot at a particular point in time. Peaks and dips in performance are then measured relative to this base (or trend) line which helps to identify the effect of communications or design initiatives. It also reveals seasonal variations in performance.

You need to know who your users are to be able to determine whether they are likely to need [assisted digital](http://digital.cabinetoffice.gov.uk/2012/05/30/getting-started-on-assisted-digital/) to help them use the digital service. The proportion of users needing assisted digital will vary based on the users of the particular service. For example, a higher proportion of people applying for incapacity benefits are more likely to need assistance with digital services than those needing to pay their road tax.

Combining data often reveals useful insights, for example into service efficiency (eg cost per transaction and total cost to serve) or proportional usage by channel (eg percentage digital uptake vs post, phone etc).

Be aware though that combining data from different data sources can lead to huge storage requirements: large, data-driven organisations now talk about storage in terms of petabytes, the equivalent of one million gigabytes. However, there are cost-effective solutions to this problem already in place. For example, the [Hadoop](http://hadoop.apache.org/) software framework was developed to enable collection, aggregation and querying of such huge data stores, and is based on [work done by Google](http://en.wikipedia.org/wiki/MapReduce) and Yahoo to develop search engines.

Benchmarking against other services can also provide a useful context for judging performance. By comparing to other similar services (e.g. requesting a license or reporting information) you know whether the service is significantly better or worse than expected. A [complete list](https://www.gov.uk/performance/transactional-services) of the governmentâ€™s transactional services is available on GOV.UK.

##Further reading
[Great article](http://radar.oreilly.com/2010/06/what-is-data-science.html) by Mike Loukides on the role of the data scientist.

[These webinars](http://www.cloudera.com/blog/2011/01/2010-cloudera-apache-hadoop-webinars/) by Cloudera provide a useful introduction to Hadoop.

Total Cost to Serve is a [method (PDF, 79k)](http://www.hmrc.gov.uk/research/cost-of-time.pdf) for calculating the cost of a transaction for both the service provider and the user. HMRC have developed a method for calculating the cost of users time when interacting with government. This is important because some channels may be quicker to use than others.

[This article](http://www.guardian.co.uk/money/2010/dec/22/amazon-top-consumer-satisfaction) in The Guardian shows online customer satisfaction scores for retailers. These scores are based on the Customer Satisfaction Index.
