---
layout: wide
title: The Digital by Default Standard
subtitle: Services so good that people prefer to use them
type: guide
audience:
  primary: service-manager
  secondary: designer, developer, tech-arch, analyst, researcher
theme: getting-started
section: dbd
status: draft
---

To achieve the Digital by Default Service Standard, the service team must demonstrate that they have:

* conducted research to develop a deep knowledge of who the service users are, what the user needs are, and what that implies for their digital and assisted digital service design 
* created a multidisciplinary team, led by a single, suitably skilled and empowered Service Manager
* considered the data and information the service will be providing or storing, and addressed the security level, legal responsibilities and risks associated with the service
* considered the tools and systems they will be using to build, host, operate and measure their service, and how to procure them
* built a prototype, using the agile, iterative and user-centred methods set out in the Government Service Design Manual (GSDM)
* established performance benchmarks to define success in consultation with GDS, using the 4 key indicators (KPIs) defined in the GSDM against which the service will be measured 
* analysed the prototype service’s success and ensured that user feedback is translated into features for the next phase of development
* created a service that is simple and intuitive enough that all users succeed first time, unaided, and procured appropriate assisted digital support
* if needed, considered the seamless integration of the service’s digital and non-digital stages
* used the Government Service Design Manual to develop the content and design to ensure the service has the same look, feel and tone as GOV.UK
developed a plan and targets for online take-up and the service’s assisted digital user needs
* got the capacity and technical flexibility to update and improve the service on a daily basis
* made all new code open, reuseable and published under appropriate licenses 
* built a safe service that protects user data and privacy, and operates at appropriate security levels
* used open standards and common Government platforms (e.g. Identity Assurance) where available 
* an ongoing ability to test the end-to-end service as if it were in an environment identical to that of the live version, with dummy accounts and a representative sample of potential service users, on all common browsers and devices
* instrumented analytics tools and ensured that performance data is collectable
* analysed the prototype service’s success and ensured that user feedback and performance data is translated into features for the next phase of development
* built and resourced a service that can be improved daily, based on user research and KPI data
* a plan in place for ongoing user testing, including the ability to support multivariate experiments
* put in place a multidisciplinary team, led by a single, suitably skilled and empowered service manager, to operate and run the live service
achieved, and will continue to achieve, high levels of user satisfaction across the digital and assisted digital service that are reported on the Performance Platform (PP)
* achieved, and will continue to achieve, high transaction success rates that are reported on the PP
* a plan for, and evidence to support, achieving a low cost per transaction across the digital and assisted digital service that is reported on the PP
* a plan for, and evidence to support, achieving a high digital take-up that is reported on the PP
* a contingency ‘rollback’ plan in place should the service have to be taken offline
* successfully tested the service from beginning to end with the responsible Minister