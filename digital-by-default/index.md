---
layout: wide
title: The digital by default Standard
subtitle: Services so good that people prefer to use them
audience:
  primary: service-manager
  secondary: designer, developer, tech-arch, analyst, researcher
theme: getting-started
section: dbd
status: draft
---

The digital by default standard is currently being circulated among Digital Leaders across government. In the current draft, a team must demonstrate that they have done the following to achieve the digital by default standard:

* conducted research to develop a deep knowledge of who the service users are, what the user needs are, and what that implies for their digital and assisted digital service design 
* put in place a multidisciplinary team, led by a single, suitably skilled and empowered Service Manager, to design, build, operate and run the service
* considered the user data and information the service will be providing or storing, and addressed the security level, legal responsibilities and risks associated with the service
* considered the tools and systems they will be using to build, host, operate and measure their service, and how to procure them
* built a working prototype, using the agile, iterative and user-centred methods set out in the Government Service Design Manual (GSDM)
* established performance benchmarks to define success in consultation with GDS, using the 4 key indicators (KPIs) defined in the GSDM against which the service will be measured 
* analysed the prototype service’s success and ensured that user feedback is translated into features for the next phase of development
* created a service that is simple and intuitive enough that all users succeed first time, unaided
* put assisted digital support in place 
* a plan (developed with GDS) for the phasing out of existing alternative channels in place
* considered the seamless integration of the service’s digital and any non-digital steps that are required for legal reasons
* used the Government Service Design Manual to develop the content and design to ensure the service has the same look, feel and tone as GOV.UK
* got the capacity and technical flexibility to update and improve the service on a daily basis
* made all new code open, reuseable and published under appropriate licenses 
* used open standards and common Government platforms (e.g. Identity Assurance) where available 
* an ongoing ability to test the end-to-end service as if it were in an environment identical to that of the live version, with dummy accounts and a representative sample of potential service users, on all common browsers and devices
* instrumented analytics tools and ensured that performance data is collectable
* built and resourced a service that can be improved daily, ensuring that user feedback and performance data is translated into development
* a plan in place for ongoing user testing, including the ability to support multivariate experiments
* achieved, and will continue to achieve, high levels of user satisfaction across the digital and assisted digital service that are reported on the Performance Platform (PP)
* achieved, and will continue to achieve, high transaction success rates across the digital and assisted digital service that are reported on the PP
* a plan for, and evidence to support, achieving a low cost per transaction across the digital and assisted digital service that is reported on the PP
* a plan for, and evidence to support, achieving a high digital take-up (and targeted assisted digital support at people who really need it) that is reported on the PP
* a contingency ‘rollback’ plan in place should the service have to be taken offline
* successfully tested the service from beginning to end with the responsible Minister