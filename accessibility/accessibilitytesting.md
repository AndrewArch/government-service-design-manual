---
layout: default
title: Accessibility testing
subtitle: Testing to see if your service is inclusive
section: guidance
subsection: Accessibility 
type: guide
audience: 
    primary: researcher
    secondary: designer, developer
theme: Measurement
status: draft
assets: local
---

This guidance looks at how accessibility testing should be conducted to ensure that new products/services are built with all users in mind.

##Guidance

Accessibility testing is much like usability testing, in that it is about ensuring that a product or service is easy to use for it’s intended audience. That audience  includes ‘disabled’ users who may access the service via a range of assistive technologies such as screen readers, voice recognition software, trackball devices etc

It’s important to take a range of disabilities into account when you are testing any product or service including those with;

*  Cognitive and learning disabilities e.g. dyslexia or attention deficit disorders

*  Visual impairments e.g. total and partial blindness, colour blindness, poor vision 

*  Auditory disabilities which can also affect language 

*  Motor skills impairments e.g. those affected by arthritis, strokes, RSI

The Section III of the Disability Discrimination Act (DDA), also states that websites should be accessible to blind and disabled users and the Code of Practice for this section of the DDA was published on 27th May 2002.

NB. This does not include Accessibility Audits

An accessibility audit involves an accessibility expert reviewing the site or service, highlighting all accessibility issues and providing recommendations for fixing them. They would typically use assistive software used by disabled web users (e.g. a screen reader) to effectively carry out the audit. See W3C accessibility guidelines for further information.

Accessibility audits are cheaper and quicker than accessibility testing but rely primarily on the expertise of the person conducting them.


##Where/how you might use it

Most typically conducted after an accessibility audit has been conducted.

Accessibility testing with ‘real’ participants with a range of ‘disabilities’ is best conducted in the  participants own homes. This is because they will often have things set up to suit their individual needs and the whole process is less stressful for them e.g. travel, environment.

##Weaknesses/when not to use

Often cannot be conducted early on in the service lifecycle. The service must be fairly robust in order for it to be evaluated by people using assistive technologies e.g. a screen reader, such as Jaws, will read out the contents of a web page so the code needs to be well structured. Real content needs to be in place rather than ‘dummy text’, if it is to be assessed by those with any cognitive or learning difficulties. Interactive elements such as Calls To Action, hyperlinks, forms etc must be in place if motor skills are being assessed.

Full lab-based accessibility testing is not required for every project. An accessibility audit would be a more efficient and cost-effective way to review a site.

##No./Types of participants

Disabled participants can be included as part of a wider user testing recruit. However, the numbers will be small but should aim to capture a range of disabilities and ‘assistive technologies’.  

##Cost

This is a harder to reach audience so costs can be more expensive. Recruitment is best conducted through specialist organisations or agencies e.g. AbilityNet, RNIB etc

Additional costs can be incurred if these participants are travelling to your testing location and/or require specialist assistance with carers or travel.

##Timescales
Dependent on project scope, availability of ‘robust’ testing assets
Recruitment via an agency can take up to 2 weeks but may be more depending on the target audience. Specialist agencies / organisations / charities can help with recruitment.
Conducting testing sessions can take between 2-3 days depending on how many participants have been scheduled. This may vary depending on whether the sessions are lab-based or structured sessions in a ‘home environment’. Analysis and reporting can take up to a week.
