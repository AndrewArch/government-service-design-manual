---
layout: default
title: User satisfaction
section: guidance
subsection: KPIs
status: draft
---
    
Defined as the percentage of people who answered either “very satisfied” or “satisfied” on a five-point scale in response to the question:

> Q: Overall, how satisfied are you with your visit to the online [e.g. car tax] service today?

> A: 
> Very satisfied 
> Satisfied 
> Neither satisfied or dissatisfied 
> Dissatisfied
> Very dissatisfied

## Why measure user satisfaction?

A good service enables users to complete tasks successfully. A great service is also enjoyable to use.  Satisfaction provides a qualitative measure of how satisfying the experience is. Many government transactions are mandatory and therefore not inherently enjoyable - sometimes referred to as grudge transactions - but you should endeavour to make them as pleasant as possible for users, who may be nervous or stressed when interacting with the government.

Asking users how satisfied they are with a service can provide a measure of all the elements contributing to the overall user experience such as ease of use, navigation and design.

## How to Measure User Satisfaction

GOV.UK will provide a user satisfaction survey at the end of service and feed the results into the performance platform. 

## What happens if a user exits the transaction mid way through?

You should measure all user journeys through your transaction to understand drop off points. GDS will provide dropout survey if they fail to complete a transaction. 

This survey will collect further qualitative data For example: ‘Please tell us why are you unable to complete this transaction.’ 

Although this survey will not be contribute to the overall measure of user satisfaction it will help you understand service drop of points and find ways to improve transactions.

## When to measure user satisfaction

In order to successfully measure the user satisfaction of your service we recommend you follow the guidance below:

Inception

* Benchmark the existing service for future comparison
* Develop a plan to measure user satisfaction throughout product development

Alpha

* Benchmark user satisfaction via remote usability testing and/or a satisfaction survey

Beta

* Measure user satisfaction via remote usability testing and/or satisfaction survey
* Identify why people are dissatisfied or not completing transactions and take steps to improve

Live

* Measure user satisfaction continually and monitor results on at least a monthly basis
* Carry out a more comprehensive user demographics, usage and attitudes survey every six months


## What about post launch?

A exit survey will be run continuously on your service, and report satisfaction on a monthly basis. You can use this data to improve your service.

You should also carry out a more comprehensive user satisfaction survey every six months.

You could also consider doing a drivers analysis of the key factors driving satisfaction with the service. For example, by asking additional questions (e.g. on ease of use, accuracy, look and feel) you can determine which of those factors is most positively contributing to user satisfaction and hence prioritise where to focus ongoing design efforts.

## Further reading
[Survey design](users/surveydesign.html)